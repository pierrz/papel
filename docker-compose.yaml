# Basic Airflow cluster configuration for CeleryExecutor with Redis and PostgreSQL.
#
# WARNING: This configuration is for local development. Do not use it in a production deployment.
#
# This configuration supports basic configuration using environment variables or an .env file
# The following variables are supported:
#
# AIRFLOW_IMAGE_NAME         - Docker image name used to run Airflow.
#                              Default: apache/airflow:master-python3.8
# AIRFLOW_UID                - User ID in Airflow containers
#                              Default: 50000
# AIRFLOW_GID                - Group ID in Airflow containers
#                              Default: 50000
# _AIRFLOW_WWW_USER_USERNAME - Username for the administrator account.
#                              Default: airflow
# _AIRFLOW_WWW_USER_PASSWORD - Password for the administrator account.
#                              Default: airflow
#

---
version: '3.8'
x-airflow-common:
  &airflow-common
  image: "${AIRFLOW_IMAGE_NAME:-apache/airflow:2.0.1-python3.8}"
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: "CeleryExecutor"
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ""
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
    AIRFLOW__CORE__LOAD_EXAMPLES: "true"
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
  user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-50000}"
  depends_on:
    redis:
      condition: "service_healthy"
    postgres:
      condition: "service_healthy"

services:

  pgadmin:
    container_name: "pgadmin4_container"
    image: "dpage/pgadmin4"
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: "pgadmin@pg.com"
      PGADMIN_DEFAULT_PASSWORD: "pgadmin"
    ports:
      - "5050:80"
  
  # source db
  mongo:
    image: "mongo:latest"
    restart: always
    environment:
      MONGO_INITDB_DATABASE: "source"
      MONGO_INITDB_ROOT_USERNAME: "mongou"
      MONGO_INITDB_ROOT_PASSWORD: "mongou"
    volumes:
      - data-volume:/etc/data/dev_db

  mongo-express:
    image: "mongo-express:latest"
    restart: always
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: "mongoadmin"
      ME_CONFIG_MONGODB_ADMINPASSWORD: "mongoadmin"
    volumes:  
      - backend-volume:/var/lib/mongo

  # dev db
  postgres-dev:
    container_name: "devdb_container"
    image: "postgres:13"
    environment:
      # POSTGRES_USER: devadmin
      POSTGRES_USER: "${DEV_DB_USER}"
      POSTGRES_PASSWORD: "${DEV_DB_PASSWORD}"
      POSTGRES_DB: "${DEV_DB}"
    volumes:  
      - data-volume:/etc/data/dev_db
      - ./create_second_db.sh:/docker-entrypoint-initdb.d/create_second_db.sh
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "devadmin"]
      interval: "5s"
      retries: 5
    restart: always
    ports:
      - "${DEV_DB_PORT}"

  # airflow
  postgres:
    container_name: "airflow_db_container"
    image: "postgres:13"
    environment:
      POSTGRES_USER: "${AIRFLOW_DB_USER}"
      POSTGRES_PASSWORD: "${AIRFLOW_DB_PASSWORD}"
      POSTGRES_DB: "${AIRFLOW_DB}"
    volumes:
      - backend-volume:/var/lib/postgresql/data   # /!\
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: "5s"
      retries: 5
    restart: always
  
  redis:
    container_name: "airflow_redis_container"
    image: "redis:latest"
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: "5s"
      timeout: "30s"
      retries: 50
    restart: always

  airflow-webserver:
    container_name: "airflow_webserver_container"
    <<: *airflow-common
    command: "webserver"
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: "10s"
      timeout: "10s"
      retries: 5
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    container_name: "airflow_scheduler_container"
    command: "scheduler"
    restart: always
    
  airflow-worker:
    <<: *airflow-common
    command: "celery worker"
    restart: always

  airflow-init:
    <<: *airflow-common
    container_name: "airflow_init_container"
    command: "version"
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: "true"
      _AIRFLOW_WWW_USER_CREATE: "true"
      _AIRFLOW_WWW_USER_USERNAME: "${_AIRFLOW_WWW_USER_USERNAME:-airflow}"
      _AIRFLOW_WWW_USER_PASSWORD: "${_AIRFLOW_WWW_USER_PASSWORD:-airflow}"

  flower:
    <<: *airflow-common
    container_name: "airflow_celery_container"
    command: "celery flower"
    ports:
      - "5555:5555"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: "10s"
      timeout: "10s"
      retries: 5
    restart: always

volumes:
  backend-volume: {}
  data-volume: {}
